{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d80b8e9-ad2f-4753-846e-3b4e03de9c23",
   "metadata": {},
   "source": [
    "# SCENIC+: Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c3ea4a-7237-4f95-aa78-f8799607c913",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23f516c9-b1da-4a60-9801-713eb1afb500",
   "metadata": {
    "tags": []
   },
   "source": [
    "# SCENIC+: Step-by-step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b77da0-5c8e-4bab-8711-bd20147d920a",
   "metadata": {},
   "source": [
    "## 1. Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67e64e32-8312-4fdc-b306-9766517a6fc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T06:02:52.185485Z",
     "iopub.status.busy": "2023-01-15T06:02:52.185149Z",
     "iopub.status.idle": "2023-01-15T06:02:52.193147Z",
     "shell.execute_reply": "2023-01-15T06:02:52.192431Z",
     "shell.execute_reply.started": "2023-01-15T06:02:52.185456Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import sys\n",
    "import os\n",
    "_stderr = sys.stderr\n",
    "null = open(os.devnull,'wb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f40e933-f575-46e9-9f9e-126c24d030ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T06:02:52.737176Z",
     "iopub.status.busy": "2023-01-15T06:02:52.736854Z",
     "iopub.status.idle": "2023-01-15T06:02:53.823067Z",
     "shell.execute_reply": "2023-01-15T06:02:53.821925Z",
     "shell.execute_reply.started": "2023-01-15T06:02:52.737148Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 33K\n",
      "drwxr-xr-x 3 aklie carter-users   1 Jan  5 10:03 ENCFF035SPT\n",
      "drwxr-xr-x 3 aklie carter-users   1 Jan  5 10:03 ENCFF042ZJI\n",
      "drwxr-xr-x 3 aklie carter-users   1 Jan  5 10:04 ENCFF101BLM\n",
      "drwxr-xr-x 3 aklie carter-users   1 Jan  5 10:04 ENCFF119IVK\n",
      "drwxr-xr-x 3 aklie carter-users   1 Jan  5 10:04 ENCFF176LJV\n",
      "drwxr-xr-x 3 aklie carter-users   1 Jan  5 10:04 ENCFF187VMN\n",
      "drwxr-xr-x 3 aklie carter-users   1 Jan  5 10:04 ENCFF622EUO\n",
      "drwxr-xr-x 3 aklie carter-users   1 Jan  5 10:05 ENCFF683IBE\n",
      "-rw-r--r-- 1 aklie carter-users 29K Jan  5 09:55 metadata.tsv\n"
     ]
    }
   ],
   "source": [
    "!ls -lh /cellar/users/aklie/data/igvf/topic_grn_links/mouse_adrenal/encode/fragments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09ecaf39-927d-4fa1-8198-f091c5fba696",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T06:02:53.824904Z",
     "iopub.status.busy": "2023-01-15T06:02:53.824603Z",
     "iopub.status.idle": "2023-01-15T06:02:54.914043Z",
     "shell.execute_reply": "2023-01-15T06:02:54.912908Z",
     "shell.execute_reply.started": "2023-01-15T06:02:53.824871Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 aklie carter-users 801M Jan 13 09:46 /cellar/users/aklie/data/igvf/topic_grn_links/mouse_adrenal/preprocess/snrna/filtered.h5ad\n"
     ]
    }
   ],
   "source": [
    "!ls -lh /cellar/users/aklie/data/igvf/topic_grn_links/mouse_adrenal/preprocess/snrna/filtered.h5ad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d807f9-70da-4109-805d-b29bc818aff7",
   "metadata": {},
   "source": [
    "## 2. scRNA-seq analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee54ac2f-77ff-4c67-9087-f060c16a5a09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T06:02:54.916748Z",
     "iopub.status.busy": "2023-01-15T06:02:54.916268Z",
     "iopub.status.idle": "2023-01-15T06:02:54.921254Z",
     "shell.execute_reply": "2023-01-15T06:02:54.920469Z",
     "shell.execute_reply.started": "2023-01-15T06:02:54.916696Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "work_dir = 'mouse_adrenal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49381e16-3953-43d9-968a-b68c492bb145",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T06:02:54.922581Z",
     "iopub.status.busy": "2023-01-15T06:02:54.922258Z",
     "iopub.status.idle": "2023-01-15T06:03:06.753155Z",
     "shell.execute_reply": "2023-01-15T06:03:06.752124Z",
     "shell.execute_reply.started": "2023-01-15T06:02:54.922555Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "#set some figure parameters for nice display inside jupyternotebooks.\n",
    "%matplotlib inline\n",
    "sc.settings.set_figure_params(dpi=80, frameon=False, figsize=(5, 5), facecolor='white')\n",
    "\n",
    "#make a directory for to store the processed scRNA-seq data.\n",
    "if not os.path.exists(os.path.join(work_dir, 'scRNA')):\n",
    "    os.makedirs(os.path.join(work_dir, 'scRNA'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ebbe00d-7cee-407a-98f9-54cba152b490",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T06:03:06.755835Z",
     "iopub.status.busy": "2023-01-15T06:03:06.755127Z",
     "iopub.status.idle": "2023-01-15T06:03:32.426883Z",
     "shell.execute_reply": "2023-01-15T06:03:32.425832Z",
     "shell.execute_reply.started": "2023-01-15T06:03:06.755804Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 79209 × 47721\n",
       "    obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'cellID', 'doublet_scores', 'doublets', 'library_accession', 'technology', 'species', 'tissue', 'sex', 'timepoint', 'rep', 'sample', 'depth1', 'depth2', 'experiment', 'experiment_batch', 'integration_batch', 'run_number', 'experiment_accession', 'file_accession', 'lower_nCount_RNA', 'upper_nCount_RNA', 'lower_nFeature_RNA', 'upper_doublet_scores', 'upper_percent.mt', 'percent.mt', 'percent.ribo', 'nCount_SCT', 'nFeature_SCT', 'integrated_snn_res.1.6', 'seurat_clusters', 'S.Score', 'G2M.Score', 'Phase', 'subtypes', 'celltypes', 'gen_celltype', 'Cortex_membership_score', 'Endothelial_membership_score', 'Adipocytes_membership_score', 'Myeloid_membership_score', 'Sox10._membership_score', 'Fibroblast_membership_score', 'Medulla_membership_score', 'Stromal_membership_score', 'Smooth_muscle_membership_score', 'Capsule_membership_score', 'Hepatocyte_membership_score', 'Myonuclei_membership_score', 'gen_celltype_membership_score'\n",
       "    var: 'features'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata = sc.read_h5ad(os.path.join(work_dir, 'data/adata.h5ad'))\n",
    "adata.var_names_make_unique()\n",
    "adata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b103364-1c33-4fb1-91eb-d7c3a243a2a4",
   "metadata": {},
   "source": [
    "## 3. scATAC-seq analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b39631a-8a9a-44cc-a37c-0eeee69b112e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T06:03:32.428626Z",
     "iopub.status.busy": "2023-01-15T06:03:32.428245Z",
     "iopub.status.idle": "2023-01-15T06:03:32.448428Z",
     "shell.execute_reply": "2023-01-15T06:03:32.447596Z",
     "shell.execute_reply.started": "2023-01-15T06:03:32.428593Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pycisTopic\n",
    "#set some figure parameters for nice display inside jupyternotebooks.\n",
    "%matplotlib inline\n",
    "\n",
    "#make a directory for to store the processed scRNA-seq data.\n",
    "if not os.path.exists(os.path.join(work_dir, 'scATAC')):\n",
    "    os.makedirs(os.path.join(work_dir, 'scATAC'))\n",
    "tmp_dir = '/cellar/users/aklie/tmp/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "074f09ad-ec1d-4f76-96a3-f97d40cb22ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T06:03:32.449738Z",
     "iopub.status.busy": "2023-01-15T06:03:32.449387Z",
     "iopub.status.idle": "2023-01-15T06:03:32.489459Z",
     "shell.execute_reply": "2023-01-15T06:03:32.488660Z",
     "shell.execute_reply.started": "2023-01-15T06:03:32.449711Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob as glob\n",
    "frag_files = glob.glob(\"/cellar/users/aklie/data/igvf/topic_grn_links/mouse_adrenal/encode/fragments/*/*/*/*/*/*.tsv.gz\")\n",
    "fragments_dict = dict(zip([file.split(\"/\")[-6] for file in frag_files], frag_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bf47dde-f3cc-4930-9a93-04386418b4b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T06:03:32.490724Z",
     "iopub.status.busy": "2023-01-15T06:03:32.490391Z",
     "iopub.status.idle": "2023-01-15T06:03:32.503198Z",
     "shell.execute_reply": "2023-01-15T06:03:32.502492Z",
     "shell.execute_reply.started": "2023-01-15T06:03:32.490698Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "snatac_meta = pd.read_csv(\"/cellar/users/aklie/data/igvf/topic_grn_links/mouse_adrenal/encode/enc4_mouse_snatac_metadata.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3b90b34-b9de-42ed-8fd0-455eccc80f75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T06:03:32.504439Z",
     "iopub.status.busy": "2023-01-15T06:03:32.504119Z",
     "iopub.status.idle": "2023-01-15T06:03:32.508140Z",
     "shell.execute_reply": "2023-01-15T06:03:32.507384Z",
     "shell.execute_reply.started": "2023-01-15T06:03:32.504413Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cell_data = adata.obs\n",
    "del(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ba4dc7d-dc78-494c-9eb6-4e466fd8516d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T06:03:32.509996Z",
     "iopub.status.busy": "2023-01-15T06:03:32.509453Z",
     "iopub.status.idle": "2023-01-15T06:03:32.577304Z",
     "shell.execute_reply": "2023-01-15T06:03:32.576255Z",
     "shell.execute_reply.started": "2023-01-15T06:03:32.509954Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1990380/2069487882.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cell_data[\"sample_id\"] = cell_data[\"library_accession\"].map(acc_mp).values\n",
      "/tmp/ipykernel_1990380/2069487882.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cell_data['celltype'] = cell_data['celltypes'].astype(str) # set data type of the celltype column to str, otherwise the export_pseudobulk function will complain.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ENCFF683IBE    5270\n",
       "ENCFF176LJV    5163\n",
       "ENCFF035SPT    4584\n",
       "ENCFF622EUO    4507\n",
       "ENCFF101BLM    4324\n",
       "ENCFF119IVK    3989\n",
       "ENCFF042ZJI    3987\n",
       "ENCFF187VMN    3172\n",
       "Name: sample_id, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_data = cell_data[cell_data[\"technology\"] == \"10x\"]\n",
    "acc_mp = snatac_meta.set_index(\"rna_library_accession\")[\"file_accession\"]\n",
    "cell_data[\"sample_id\"] = cell_data[\"library_accession\"].map(acc_mp).values\n",
    "cell_data['celltype'] = cell_data['celltypes'].astype(str) # set data type of the celltype column to str, otherwise the export_pseudobulk function will complain.\n",
    "cell_data[\"sample_id\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6c4fb39-1473-46ba-aebc-cbd43ccd361b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T06:03:32.583562Z",
     "iopub.status.busy": "2023-01-15T06:03:32.583054Z",
     "iopub.status.idle": "2023-01-15T06:03:32.632526Z",
     "shell.execute_reply": "2023-01-15T06:03:32.631756Z",
     "shell.execute_reply.started": "2023-01-15T06:03:32.583520Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1990380/2848274305.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cell_data[\"rna_bc\"] = [row[0] for row in cell_data[\"cellID\"].str.split(\".\")]\n"
     ]
    }
   ],
   "source": [
    "cell_data[\"rna_bc\"] = [row[0] for row in cell_data[\"cellID\"].str.split(\".\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bb91f90-be15-4e1c-9b7d-8fc5e40af64f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T06:03:32.633840Z",
     "iopub.status.busy": "2023-01-15T06:03:32.633499Z",
     "iopub.status.idle": "2023-01-15T06:03:33.509846Z",
     "shell.execute_reply": "2023-01-15T06:03:33.508941Z",
     "shell.execute_reply.started": "2023-01-15T06:03:32.633813Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rna_bcs = pd.read_csv(\"/cellar/users/aklie/data/igvf/topic_grn_links/mouse_adrenal/encode/gene_exp_737K-arc-v1.txt\", header=None)[0].values\n",
    "atac_bcs = pd.read_csv(\"/cellar/users/aklie/data/igvf/topic_grn_links/mouse_adrenal/encode/atac_737K-arc-v1.txt\", header=None)[0].values\n",
    "bcs = pd.DataFrame(data={\"rna_bcs\": rna_bcs, \"atac_bcs\": atac_bcs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "670d37d9-a7e4-4596-b7c0-74541ea32125",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T06:03:33.511242Z",
     "iopub.status.busy": "2023-01-15T06:03:33.510882Z",
     "iopub.status.idle": "2023-01-15T06:03:35.360742Z",
     "shell.execute_reply": "2023-01-15T06:03:35.359697Z",
     "shell.execute_reply.started": "2023-01-15T06:03:33.511214Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "COMPLEMENT_DNA = {\"A\": \"T\", \"C\": \"G\", \"G\": \"C\", \"T\": \"A\"}\n",
    "bcs[\"atac_bcs_rc\"] = [\"\".join(COMPLEMENT_DNA.get(base, base) for base in reversed(bc)) for bc in bcs[\"atac_bcs\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4e343ab-dca3-44e9-a855-cef92af2e7fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T06:03:35.362095Z",
     "iopub.status.busy": "2023-01-15T06:03:35.361740Z",
     "iopub.status.idle": "2023-01-15T06:03:35.491102Z",
     "shell.execute_reply": "2023-01-15T06:03:35.490351Z",
     "shell.execute_reply.started": "2023-01-15T06:03:35.362068Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bc_map = bcs.set_index(\"rna_bcs\")[\"atac_bcs_rc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a75c8b04-e0ca-4df7-84c5-d516d41fb019",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T06:03:35.492457Z",
     "iopub.status.busy": "2023-01-15T06:03:35.492097Z",
     "iopub.status.idle": "2023-01-15T06:03:35.705834Z",
     "shell.execute_reply": "2023-01-15T06:03:35.704942Z",
     "shell.execute_reply.started": "2023-01-15T06:03:35.492430Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1990380/2987911187.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cell_data[\"atac_bc\"] = cell_data[\"rna_bc\"].map(bc_map)\n"
     ]
    }
   ],
   "source": [
    "cell_data[\"atac_bc\"] = cell_data[\"rna_bc\"].map(bc_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d98e1e7-9a7b-45bc-9f2c-940b4c706e49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T06:03:35.707145Z",
     "iopub.status.busy": "2023-01-15T06:03:35.706871Z",
     "iopub.status.idle": "2023-01-15T06:03:35.724846Z",
     "shell.execute_reply": "2023-01-15T06:03:35.724126Z",
     "shell.execute_reply.started": "2023-01-15T06:03:35.707118Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1990380/370147507.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cell_data[\"atac_bc_sample\"] = cell_data[\"atac_bc\"] + \"-\" + cell_data[\"sample_id\"]\n"
     ]
    }
   ],
   "source": [
    "cell_data[\"atac_bc_sample\"] = cell_data[\"atac_bc\"] + \"-\" + cell_data[\"sample_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ca783e2-d8b3-47e7-bdd4-7826e7b60154",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T06:03:35.726051Z",
     "iopub.status.busy": "2023-01-15T06:03:35.725783Z",
     "iopub.status.idle": "2023-01-15T06:03:36.570776Z",
     "shell.execute_reply": "2023-01-15T06:03:36.569933Z",
     "shell.execute_reply.started": "2023-01-15T06:03:35.726025Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pyranges as pr\n",
    "import requests\n",
    "target_url='https://hgdownload.cse.ucsc.edu/goldenpath/mm10/bigZips/mm10.chrom.sizes'\n",
    "chromsizes=pd.read_csv(target_url, sep='\\t', header=None)\n",
    "chromsizes.columns=['Chromosome', 'End']\n",
    "chromsizes['Start']=[0]*chromsizes.shape[0]\n",
    "chromsizes=chromsizes.loc[:,['Chromosome', 'Start', 'End']]\n",
    "# Exceptionally in this case, to agree with CellRangerARC annotations\n",
    "#chromsizes['Chromosome'] = [chromsizes['Chromosome'][x].replace('v', '.') for x in range(len(chromsizes['Chromosome']))]\n",
    "#chromsizes['Chromosome'] = [chromsizes['Chromosome'][x].split('_')[1] if len(chromsizes['Chromosome'][x].split('_')) > 1 else chromsizes['Chromosome'][x] for x in range(len(chromsizes['Chromosome']))]\n",
    "chromsizes=pr.PyRanges(chromsizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f41eafdf-6763-4134-aafb-f3e5b7cd8f6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T06:03:36.572090Z",
     "iopub.status.busy": "2023-01-15T06:03:36.571729Z",
     "iopub.status.idle": "2023-01-15T06:03:36.855782Z",
     "shell.execute_reply": "2023-01-15T06:03:36.854889Z",
     "shell.execute_reply.started": "2023-01-15T06:03:36.572062Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chromosome</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr1</td>\n",
       "      <td>0</td>\n",
       "      <td>195471971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr1_GL456210_random</td>\n",
       "      <td>0</td>\n",
       "      <td>169725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr1_GL456211_random</td>\n",
       "      <td>0</td>\n",
       "      <td>241735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr1_GL456212_random</td>\n",
       "      <td>0</td>\n",
       "      <td>153618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr1_GL456213_random</td>\n",
       "      <td>0</td>\n",
       "      <td>39340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>chrY</td>\n",
       "      <td>0</td>\n",
       "      <td>91744698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>chrY_JH584300_random</td>\n",
       "      <td>0</td>\n",
       "      <td>182347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>chrY_JH584301_random</td>\n",
       "      <td>0</td>\n",
       "      <td>259875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>chrY_JH584302_random</td>\n",
       "      <td>0</td>\n",
       "      <td>155838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>chrY_JH584303_random</td>\n",
       "      <td>0</td>\n",
       "      <td>158099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "+----------------------+-----------+-----------+\n",
       "| Chromosome           | Start     | End       |\n",
       "| (category)           | (int32)   | (int32)   |\n",
       "|----------------------+-----------+-----------|\n",
       "| chr1                 | 0         | 195471971 |\n",
       "| chr1_GL456210_random | 0         | 169725    |\n",
       "| chr1_GL456211_random | 0         | 241735    |\n",
       "| chr1_GL456212_random | 0         | 153618    |\n",
       "| ...                  | ...       | ...       |\n",
       "| chrY_JH584300_random | 0         | 182347    |\n",
       "| chrY_JH584301_random | 0         | 259875    |\n",
       "| chrY_JH584302_random | 0         | 155838    |\n",
       "| chrY_JH584303_random | 0         | 158099    |\n",
       "+----------------------+-----------+-----------+\n",
       "Unstranded PyRanges object has 66 rows and 3 columns from 66 chromosomes.\n",
       "For printing, the PyRanges was sorted on Chromosome."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chromsizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da07648a-19be-451b-b0e2-f38d0bec65c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_fragments_dict = {\"ENCFF187VMN\": fragments_dict[\"ENCFF187VMN\"]}\n",
    "test_cell_data = cell_data[cell_data[\"sample_id\"] == \"ENCFF187VMN\"]\n",
    "test_cell_data[\"barcode\"] = test_cell_data[\"atac_bc\"]\n",
    "test_cell_data = test_cell_data.set_index(\"atac_bc\")\n",
    "test_fragments = pd.read_csv(test_fragments_dict[\"ENCFF187VMN\"], sep=\"\\t\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ba23d1-74d9-4e6d-8648-e8dfeecbee76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_cell_data[\"barcode\"].isin(test_fragments[3]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521173b0-e0e9-4ab5-8a24-772f51bd692f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "import sys\n",
    "from typing import Dict, List, Optional, Union\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyBigWig\n",
    "import pyranges as pr\n",
    "\n",
    "def export_pseudobulk_one_sample(\n",
    "    cell_data: pd.DataFrame,\n",
    "    group: str,\n",
    "    fragments_df_dict: Dict[str, pd.DataFrame],\n",
    "    chromsizes: pr.PyRanges,\n",
    "    bigwig_path: str,\n",
    "    bed_path: str,\n",
    "    sample_id_col: Optional[str] = \"sample_id\",\n",
    "    normalize_bigwig: Optional[bool] = True,\n",
    "    remove_duplicates: Optional[bool] = True,\n",
    "    split_pattern: Optional[str] = \"___\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Create pseudobulk as bed and bigwig from single cell fragments file given a barcode annotation and a group.\n",
    "    Parameters\n",
    "    ---------\n",
    "    cell_data: pd.DataFrame\n",
    "            A cell metadata :class:`pd.Dataframe` containing barcodes, their annotation and their sample of origin.\n",
    "    group: str\n",
    "            A character string indicating the group for which pseudobulks will be created.\n",
    "    fragments_df_dict: dict\n",
    "            A dictionary containing data frames as values with 'Chromosome', 'Start', 'End', 'Name', and 'Score' as columns; and sample label\n",
    "            as keys. 'Score' indicates the number of times that a fragments is found assigned to that barcode.\n",
    "    chromsizes: pr.PyRanges\n",
    "            A :class:`pr.PyRanges` containing size of each column, containing 'Chromosome', 'Start' and 'End' columns.\n",
    "    bigwig_path: str\n",
    "            Path to folder where the bigwig file will be saved.\n",
    "    bed_path: str\n",
    "            Path to folder where the fragments bed file will be saved.\n",
    "    sample_id_col: str, optional\n",
    "            Name of the column containing the sample name per barcode in the input :class:`CistopicObject.cell_data` or class:`pd.DataFrame`. Default: 'sample_id'.\n",
    "    normalize_bigwig: bool, optional\n",
    "            Whether bigwig files should be CPM normalized. Default: True.\n",
    "    remove_duplicates: bool, optional\n",
    "            Whether duplicates should be removed before converting the data to bigwig.\n",
    "    split_pattern: str\n",
    "            Pattern to split cell barcode from sample id. Default: ___ .\n",
    "    \"\"\"\n",
    "    # Create logger\n",
    "    level = logging.INFO\n",
    "    log_format = \"%(asctime)s %(name)-12s %(levelname)-8s %(message)s\"\n",
    "    handlers = [logging.StreamHandler(stream=sys.stdout)]\n",
    "    logging.basicConfig(level=level, format=log_format, handlers=handlers)\n",
    "    log = logging.getLogger(\"cisTopic\")\n",
    "\n",
    "    log.info(\"Creating pseudobulk for \" + str(group))\n",
    "    group_fragments_list = []\n",
    "    group_fragments_dict = {}\n",
    "    for sample_id in fragments_df_dict:\n",
    "        sample_data = cell_data[cell_data.loc[:, sample_id_col].isin([sample_id])]\n",
    "        if \"barcode\" in sample_data:\n",
    "            sample_data.index = sample_data[\"barcode\"].tolist()\n",
    "        else:\n",
    "            sample_data.index = prepare_tag_cells(\n",
    "                sample_data.index.tolist(), split_pattern\n",
    "            )\n",
    "        group_var = sample_data.iloc[:, 0]\n",
    "        barcodes = group_var[group_var.isin([group])].index.tolist()\n",
    "        print(barcodes)\n",
    "        fragments_df = fragments_df_dict[sample_id]\n",
    "        group_fragments = fragments_df.loc[fragments_df[\"Name\"].isin(barcodes)]\n",
    "        if len(fragments_df_dict) > 1:\n",
    "            group_fragments_dict[sample_id] = group_fragments\n",
    "\n",
    "    if len(fragments_df_dict) > 1:\n",
    "        group_fragments_list = [\n",
    "            group_fragments_dict[list(group_fragments_dict.keys())[x]]\n",
    "            for x in range(len(fragments_df_dict))\n",
    "        ]\n",
    "        group_fragments = group_fragments_list[0].append(group_fragments_list[1:])\n",
    "\n",
    "    del group_fragments_dict\n",
    "    del group_fragments_list\n",
    "    del fragments_df\n",
    "    gc.collect()\n",
    "\n",
    "    group_pr = pr.PyRanges(group_fragments)\n",
    "    if isinstance(bigwig_path, str):\n",
    "        bigwig_path_group = os.path.join(bigwig_path, str(group) + \".bw\")\n",
    "        if remove_duplicates:\n",
    "            group_pr.to_bigwig(\n",
    "                path=bigwig_path_group,\n",
    "                chromosome_sizes=chromsizes,\n",
    "                rpm=normalize_bigwig,\n",
    "            )\n",
    "        else:\n",
    "            group_pr.to_bigwig(\n",
    "                path=bigwig_path_group,\n",
    "                chromosome_sizes=chromsizes,\n",
    "                rpm=normalize_bigwig,\n",
    "                value_col=\"Score\",\n",
    "            )\n",
    "    if isinstance(bed_path, str):\n",
    "        print(\"here\")\n",
    "        print(group_pr)\n",
    "        bed_path_group = os.path.join(bed_path, str(group) + \".bed.gz\")\n",
    "        group_pr.to_bed(\n",
    "            path=bed_path_group, keep=False, compression=\"infer\", chain=False\n",
    "        )\n",
    "\n",
    "    log.info(str(group) + \" done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c583f5-71fb-4297-9d2f-dffe50be99f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pycisTopic.cistopic_class import *\n",
    "from pycisTopic.pseudobulk_peak_calling import export_pseudobulk_ray\n",
    "from pycisTopic.utils import read_fragments_from_file, prepare_tag_cells\n",
    "def export_pseudobulk(\n",
    "    input_data: Union[\"CistopicObject\", pd.DataFrame, Dict[str, pd.DataFrame]],\n",
    "    variable: str,\n",
    "    chromsizes: Union[pd.DataFrame, pr.PyRanges],\n",
    "    bed_path: str,\n",
    "    bigwig_path: str,\n",
    "    path_to_fragments: Optional[Dict[str, str]] = None,\n",
    "    sample_id_col: Optional[str] = \"sample_id\",\n",
    "    n_cpu: Optional[int] = 1,\n",
    "    normalize_bigwig: Optional[bool] = True,\n",
    "    remove_duplicates: Optional[bool] = True,\n",
    "    split_pattern: Optional[str] = \"___\",\n",
    "    use_polars: Optional[bool] = True,\n",
    "    **kwargs\n",
    "):\n",
    "    \"\"\"\n",
    "    Create pseudobulks as bed and bigwig from single cell fragments file given a barcode annotation.\n",
    "    Parameters\n",
    "    ---------\n",
    "    input_data: CistopicObject or pd.DataFrame\n",
    "            A :class:`CistopicObject` containing the specified `variable` as a column in :class:`CistopicObject.cell_data` or a cell metadata\n",
    "            :class:`pd.DataFrame` containing barcode as rows, containing the specified `variable` as a column (additional columns are\n",
    "            possible) and a `sample_id` column. Index names must contain the BARCODE (e.g. ATGTCGTC-1), additional tags are possible separating with -\n",
    "            (e.g. ATGCTGTGCG-1-Sample_1). The levels in the sample_id column must agree with the keys in the path_to_fragments dictionary.\n",
    "            Alternatively, if the cell metadata contains a column named barcode it will be used instead of the index names.\n",
    "    variable: str\n",
    "            A character string indicating the column that will be used to create the different group pseudobulk. It must be included in\n",
    "            the cell metadata provided as input_data.\n",
    "    chromsizes: pd.DataFrame or pr.PyRanges\n",
    "            A data frame or :class:`pr.PyRanges` containing size of each chromosome, containing 'Chromosome', 'Start' and 'End' columns.\n",
    "    bed_path: str\n",
    "            Path to folder where the fragments bed files per group will be saved. If None, files will not be generated.\n",
    "    bigwig_path: str\n",
    "            Path to folder where the bigwig files per group will be saved. If None, files will not be generated.\n",
    "    path_to_fragments: str or dict, optional\n",
    "            A dictionary of character strings, with sample name as names indicating the path to the fragments file/s from which pseudobulk profiles have to\n",
    "            be created. If a :class:`CistopicObject` is provided as input it will be ignored, but if a cell metadata :class:`pd.DataFrame` is provided it\n",
    "            is necessary to provide it. The keys of the dictionary need to match with the sample_id tag added to the index names of the input data frame.\n",
    "    sample_id_col: str, optional\n",
    "            Name of the column containing the sample name per barcode in the input :class:`CistopicObject.cell_data` or class:`pd.DataFrame`. Default: 'sample_id'.\n",
    "    n_cpu: int, optional\n",
    "            Number of cores to use. Default: 1.\n",
    "    normalize_bigwig: bool, optional\n",
    "            Whether bigwig files should be CPM normalized. Default: True.\n",
    "    remove_duplicates: bool, optional\n",
    "            Whether duplicates should be removed before converting the data to bigwig.\n",
    "    split_pattern: str, optional\n",
    "            Pattern to split cell barcode from sample id. Default: ___ .\n",
    "    use_polars: bool, optional\n",
    "            Whether to use polars to read fragments files. Default: True.\n",
    "    **kwargs\n",
    "            Additional parameters for ray.init()\n",
    "    Return\n",
    "    ------\n",
    "    dict\n",
    "            A dictionary containing the paths to the newly created bed fragments files per group a dictionary containing the paths to the\n",
    "            newly created bigwig files per group.\n",
    "    \"\"\"\n",
    "    # Create logger\n",
    "    level = logging.INFO\n",
    "    log_format = \"%(asctime)s %(name)-12s %(levelname)-8s %(message)s\"\n",
    "    handlers = [logging.StreamHandler(stream=sys.stdout)]\n",
    "    logging.basicConfig(level=level, format=log_format, handlers=handlers)\n",
    "    log = logging.getLogger(\"cisTopic\")\n",
    "\n",
    "    # Get fragments file\n",
    "    if isinstance(input_data, CistopicObject):\n",
    "        path_to_fragments = input_data.path_to_fragments\n",
    "        if path_to_fragments is None:\n",
    "            log.error(\"No path_to_fragments in this cisTopic object.\")\n",
    "        cell_data = input_data.cell_data\n",
    "    elif isinstance(input_data, pd.DataFrame):\n",
    "        if path_to_fragments is None:\n",
    "            log.error(\"Please, provide path_to_fragments.\")\n",
    "        cell_data = input_data\n",
    "    # Check for sample_id column\n",
    "    try:\n",
    "        sample_ids = list(set(cell_data[sample_id_col]))\n",
    "    except ValueError:\n",
    "        print(\n",
    "            'Please, include a sample identification column (e.g. \"sample_id\") in your cell metadata!'\n",
    "        )\n",
    "\n",
    "    # Get fragments\n",
    "    #fragments_df_dict = {}\n",
    "    \"\"\"\n",
    "    for sample_id in path_to_fragments.keys():\n",
    "        if sample_id not in sample_ids:\n",
    "            log.info(\n",
    "                \"The following path_to_fragments entry is not found in the cell metadata sample_id_col: \",\n",
    "                sample_id,\n",
    "                \". It will be ignored.\",\n",
    "            )\n",
    "        else:\n",
    "            log.info(\"Reading fragments from \" + path_to_fragments[sample_id])\n",
    "            fragments_df = read_fragments_from_file(path_to_fragments[sample_id], use_polars=use_polars).df\n",
    "            # Convert to int32 for memory efficiency\n",
    "            fragments_df.Start = np.int32(fragments_df.Start)\n",
    "            fragments_df.End = np.int32(fragments_df.End)\n",
    "            if \"Score\" in fragments_df:\n",
    "                fragments_df.Score = np.int32(fragments_df.Score)\n",
    "            if \"barcode\" in cell_data:\n",
    "                fragments_df = fragments_df.loc[\n",
    "                    fragments_df[\"Name\"].isin(cell_data[\"barcode\"].tolist())\n",
    "                ]\n",
    "            else:\n",
    "                fragments_df = fragments_df.loc[\n",
    "                    fragments_df[\"Name\"].isin(\n",
    "                        prepare_tag_cells(cell_data.index.tolist(), split_pattern)\n",
    "                    )\n",
    "                ]\n",
    "            fragments_df_dict[sample_id] = fragments_df\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set groups\n",
    "    if \"barcode\" in cell_data:\n",
    "        cell_data = cell_data.loc[:, [variable, sample_id_col, \"barcode\"]]\n",
    "    else:\n",
    "        cell_data = cell_data.loc[:, [variable, sample_id_col]]\n",
    "    cell_data[variable] = cell_data[variable].replace(\" \", \"\", regex=True)\n",
    "    cell_data[variable] = cell_data[variable].replace(\"[^A-Za-z0-9]+\", \"_\", regex=True)\n",
    "    groups = sorted(list(set(cell_data[variable])))\n",
    "    groups = groups[:2]\n",
    "    print(groups)\n",
    "    # Check chromosome sizes\n",
    "    if isinstance(chromsizes, pd.DataFrame):\n",
    "        chromsizes = chromsizes.loc[:, [\"Chromosome\", \"Start\", \"End\"]]\n",
    "        chromsizes = pr.PyRanges(chromsizes)\n",
    "    # Check that output dir exist and generate output paths\n",
    "    if isinstance(bed_path, str):\n",
    "        if not os.path.exists(bed_path):\n",
    "            os.makedirs(bed_path)\n",
    "        bed_paths = {\n",
    "            group: os.path.join(bed_path, str(group) + \".bed.gz\") for group in groups\n",
    "        }\n",
    "    else:\n",
    "        bed_paths = {}\n",
    "    if isinstance(bigwig_path, str):\n",
    "        if not os.path.exists(bigwig_path):\n",
    "            os.makedirs(bigwig_path)\n",
    "        bw_paths = {\n",
    "            group: os.path.join(bigwig_path, str(group) + \".bw\") for group in groups\n",
    "        }\n",
    "    else:\n",
    "        bw_paths = {}\n",
    "    # Create pseudobulks\n",
    "    print(cell_data)\n",
    "    print(groups)\n",
    "    print(fragments_df_dict)\n",
    "    print(chromsizes)\n",
    "    print(bigwig_path, bed_path)\n",
    "    print(sample_id_col)\n",
    "    if n_cpu > 1:\n",
    "        ray.init(num_cpus=n_cpu, **kwargs)\n",
    "        ray_handle = ray.wait(\n",
    "            [\n",
    "                export_pseudobulk_ray.remote(\n",
    "                    cell_data,\n",
    "                    group,\n",
    "                    fragments_df_dict,\n",
    "                    chromsizes,\n",
    "                    bigwig_path,\n",
    "                    bed_path,\n",
    "                    sample_id_col,\n",
    "                    normalize_bigwig,\n",
    "                    remove_duplicates,\n",
    "                    split_pattern,\n",
    "                )\n",
    "                for group in groups\n",
    "            ],\n",
    "            num_returns=len(groups),\n",
    "        )\n",
    "        ray.shutdown()\n",
    "    else:\n",
    "        [\n",
    "            export_pseudobulk_one_sample(\n",
    "                cell_data,\n",
    "                group,\n",
    "                fragments_df_dict,\n",
    "                chromsizes,\n",
    "                bigwig_path,\n",
    "                bed_path,\n",
    "                sample_id_col,\n",
    "                normalize_bigwig,\n",
    "                remove_duplicates,\n",
    "                split_pattern,\n",
    "            )\n",
    "            for group in groups\n",
    "        ]\n",
    "\n",
    "    return bw_paths, bed_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e133a4-2d4b-4e4f-95ae-b2714d4d4a7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bw_paths, bed_paths = export_pseudobulk(\n",
    "    input_data = test_cell_data,\n",
    "    variable = 'celltypes', # variable by which to generate pseubulk profiles, in this case we want pseudobulks per celltype\n",
    "    sample_id_col = 'sample_id',\n",
    "    chromsizes = chromsizes,\n",
    "    bed_path = os.path.join(work_dir, 'scATAC/consensus_peak_calling/pseudobulk_bed_files/'),  # specify where pseudobulk_bed_files should be stored\n",
    "    bigwig_path = os.path.join(work_dir, 'scATAC/consensus_peak_calling/pseudobulk_bw_files/'), # specify where pseudobulk_bw_files should be stored\n",
    "    path_to_fragments = test_fragments_dict, # location of fragment fiels\n",
    "    n_cpu = 1, # specify the number of cores to use, we use ray for multi processing\n",
    "    normalize_bigwig = True,\n",
    "    remove_duplicates = True,\n",
    "    _temp_dir = os.path.join(tmp_dir, 'ray_spill'),\n",
    "    split_pattern = '-'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2acd5b-0f24-4d8a-851e-cbd5eb87c415",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pycisTopic.pseudobulk_peak_calling import export_pseudobulk\n",
    "bw_paths, bed_paths = export_pseudobulk(\n",
    "    input_data = cell_data,\n",
    "    variable = 'celltype', # variable by which to generate pseubulk profiles, in this case we want pseudobulks per celltype\n",
    "    sample_id_col = 'sample_id',\n",
    "    chromsizes = chromsizes,\n",
    "    bed_path = os.path.join(work_dir, 'scATAC/consensus_peak_calling/pseudobulk_bed_files/'),  # specify where pseudobulk_bed_files should be stored\n",
    "    bigwig_path = os.path.join(work_dir, 'scATAC/consensus_peak_calling/pseudobulk_bw_files/'), # specify where pseudobulk_bw_files should be stored\n",
    "    path_to_fragments = fragments_dict, # location of fragment fiels\n",
    "    n_cpu = 12, # specify the number of cores to use, we use ray for multi processing\n",
    "    normalize_bigwig = True,\n",
    "    remove_duplicates = True,\n",
    "    _temp_dir = os.path.join(tmp_dir, 'ray_spill'),\n",
    "    split_pattern = '-'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803bab3a-d0c9-4045-b99b-9a6bb3be0dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38855215-68cc-4660-8b10-962ddddd94fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_to_fragments = test_fragments_dict\n",
    "sample_id_col = \"sample_id\"\n",
    "variable = \"celltypes\"\n",
    "sample_ids = list(set(cell_data[sample_id_col]))\n",
    "use_polars = True\n",
    "level = logging.INFO\n",
    "log_format = \"%(asctime)s %(name)-12s %(levelname)-8s %(message)s\"\n",
    "handlers = [logging.StreamHandler(stream=sys.stdout)]\n",
    "logging.basicConfig(level=level, format=log_format, handlers=handlers)\n",
    "log = logging.getLogger(\"cisTopic\")\n",
    "cell_data = test_cell_data\n",
    "bed_path = os.path.join(work_dir, 'scATAC/consensus_peak_calling/pseudobulk_bed_files/')\n",
    "bigwig_path = os.path.join(work_dir, 'scATAC/consensus_peak_calling/pseudobulk_bw_files/'),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf2f696-d0a0-4493-b4e0-9ae5a57eef70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pycisTopic.utils import read_fragments_from_file, prepare_tag_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd580c98-c27c-4496-808b-1c7a6625470b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f1a442-3511-4522-9b62-e0e8ca7bf72c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fragments_df_dict = {}\n",
    "for sample_id in path_to_fragments.keys():\n",
    "    if sample_id not in sample_ids:\n",
    "        log.info(\n",
    "            \"The following path_to_fragments entry is not found in the cell metadata sample_id_col: \",\n",
    "            sample_id,\n",
    "            \". It will be ignored.\",\n",
    "        )\n",
    "    else:\n",
    "        log.info(\"Reading fragments from \" + path_to_fragments[sample_id])\n",
    "\n",
    "        fragments_df = read_fragments_from_file(path_to_fragments[sample_id], use_polars=use_polars).df\n",
    "        # Convert to int32 for memory efficiency\n",
    "        fragments_df.Start = np.int32(fragments_df.Start)\n",
    "        fragments_df.End = np.int32(fragments_df.End)\n",
    "        if \"Score\" in fragments_df:\n",
    "            fragments_df.Score = np.int32(fragments_df.Score)\n",
    "        if \"barcode\" in cell_data:\n",
    "            fragments_df = fragments_df.loc[\n",
    "                fragments_df[\"Name\"].isin(cell_data[\"barcode\"].tolist())\n",
    "            ]\n",
    "        else:\n",
    "            fragments_df = fragments_df.loc[\n",
    "                fragments_df[\"Name\"].isin(\n",
    "                    prepare_tag_cells(cell_data.index.tolist(), split_pattern)\n",
    "                )\n",
    "            ]\n",
    "        fragments_df_dict[sample_id] = fragments_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc81a8b1-1951-401d-a443-8f5e708ad774",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5877a968-0f03-4a17-816d-15e6d687c888",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if \"barcode\" in cell_data:\n",
    "    cell_data = cell_data.loc[:, [variable, sample_id_col, \"barcode\"]]\n",
    "else:\n",
    "    cell_data = cell_data.loc[:, [variable, sample_id_col]]\n",
    "cell_data[variable] = cell_data[variable].replace(\" \", \"\", regex=True)\n",
    "cell_data[variable] = cell_data[variable].replace(\"[^A-Za-z0-9]+\", \"_\", regex=True)\n",
    "groups = sorted(list(set(cell_data[variable])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350b078a-7a31-42b5-bbd3-172da81ce46c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cell_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1da2a9f-5dd1-4971-9ba5-dd56ef8af4e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "group = groups[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607d6ea8-6929-473b-86da-38e8c1e6446d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "level = logging.INFO\n",
    "log_format = \"%(asctime)s %(name)-12s %(levelname)-8s %(message)s\"\n",
    "handlers = [logging.StreamHandler(stream=sys.stdout)]\n",
    "logging.basicConfig(level=level, format=log_format, handlers=handlers)\n",
    "log = logging.getLogger(\"cisTopic\")\n",
    "\n",
    "log.info(\"Creating pseudobulk for \" + str(group))\n",
    "group_fragments_list = []\n",
    "group_fragments_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002fdce3-5922-4136-8efc-a189e9fddf91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "log.info(\"Creating pseudobulk for \" + str(group))\n",
    "group_fragments_list = []\n",
    "group_fragments_dict = {}\n",
    "for sample_id in fragments_df_dict:\n",
    "    print(sample_id)\n",
    "    sample_data = cell_data[cell_data.loc[:, sample_id_col].isin([sample_id])]\n",
    "    if \"barcode\" in sample_data:\n",
    "        sample_data.index = sample_data[\"barcode\"].tolist()\n",
    "    else:\n",
    "        sample_data.index = prepare_tag_cells(\n",
    "            sample_data.index.tolist(), split_pattern\n",
    "        )\n",
    "    group_var = sample_data.iloc[:, 0]\n",
    "    barcodes = group_var[group_var.isin([group])].index.tolist()\n",
    "    fragments_df = fragments_df_dict[sample_id]\n",
    "    group_fragments = fragments_df.loc[fragments_df[\"Name\"].isin(barcodes)]\n",
    "    if len(fragments_df_dict) > 1:\n",
    "        group_fragments_dict[sample_id] = group_fragments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8d8119-a69e-4f65-96ba-15e322154473",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8472e7c-31bf-492a-9317-977a5a9e5116",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_data = cell_data[cell_data.loc[:, sample_id_col].isin([sample_id])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b023c7e0-db2e-4bf8-bd2d-8b3814dc38c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(fragments_df_dict) > 1:\n",
    "        group_fragments_list = [\n",
    "            group_fragments_dict[list(group_fragments_dict.keys())[x]]\n",
    "            for x in range(len(fragments_df_dict))\n",
    "        ]\n",
    "        group_fragments = group_fragments_list[0].append(group_fragments_list[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b38686e-b59c-404c-898b-660fc86a3c55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "del group_fragments_dict\n",
    "del group_fragments_list\n",
    "del fragments_df\n",
    "gc.collect()\n",
    "\n",
    "group_pr = pr.PyRanges(group_fragments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f38bc7-2435-4ff2-af08-e1f122bec714",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19af44fa-2429-4cd5-8cda-83a6a8e3b67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(bigwig_path, str):\n",
    "    bigwig_path_group = os.path.join(bigwig_path, str(group) + \".bw\")\n",
    "    if remove_duplicates:\n",
    "        group_pr.to_bigwig(\n",
    "            path=bigwig_path_group,\n",
    "            chromosome_sizes=chromsizes,\n",
    "            rpm=normalize_bigwig,\n",
    "        )\n",
    "    else:\n",
    "        group_pr.to_bigwig(\n",
    "            path=bigwig_path_group,\n",
    "            chromosome_sizes=chromsizes,\n",
    "            rpm=normalize_bigwig,\n",
    "            value_col=\"Score\",\n",
    "        )\n",
    "if isinstance(bed_path, str):\n",
    "    print(\"here\")\n",
    "    print(group_pr)\n",
    "    bed_path_group = os.path.join(bed_path, str(group) + \".bed.gz\")\n",
    "    group_pr.to_bed(\n",
    "        path=bed_path_group, keep=False, compression=\"infer\", chain=False\n",
    "    )\n",
    "\n",
    "log.info(str(group) + \" done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3114acf3-527c-4202-8401-92597f60eeae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "import sys\n",
    "from typing import Dict, List, Optional, Union\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyBigWig\n",
    "import pyranges as pr\n",
    "\n",
    "def export_pseudobulk_one_sample(\n",
    "    cell_data: pd.DataFrame,\n",
    "    group: str,\n",
    "    fragments_df_dict: Dict[str, pd.DataFrame],\n",
    "    chromsizes: pr.PyRanges,\n",
    "    bigwig_path: str,\n",
    "    bed_path: str,\n",
    "    sample_id_col: Optional[str] = \"sample_id\",\n",
    "    normalize_bigwig: Optional[bool] = True,\n",
    "    remove_duplicates: Optional[bool] = True,\n",
    "    split_pattern: Optional[str] = \"___\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Create pseudobulk as bed and bigwig from single cell fragments file given a barcode annotation and a group.\n",
    "    Parameters\n",
    "    ---------\n",
    "    cell_data: pd.DataFrame\n",
    "            A cell metadata :class:`pd.Dataframe` containing barcodes, their annotation and their sample of origin.\n",
    "    group: str\n",
    "            A character string indicating the group for which pseudobulks will be created.\n",
    "    fragments_df_dict: dict\n",
    "            A dictionary containing data frames as values with 'Chromosome', 'Start', 'End', 'Name', and 'Score' as columns; and sample label\n",
    "            as keys. 'Score' indicates the number of times that a fragments is found assigned to that barcode.\n",
    "    chromsizes: pr.PyRanges\n",
    "            A :class:`pr.PyRanges` containing size of each column, containing 'Chromosome', 'Start' and 'End' columns.\n",
    "    bigwig_path: str\n",
    "            Path to folder where the bigwig file will be saved.\n",
    "    bed_path: str\n",
    "            Path to folder where the fragments bed file will be saved.\n",
    "    sample_id_col: str, optional\n",
    "            Name of the column containing the sample name per barcode in the input :class:`CistopicObject.cell_data` or class:`pd.DataFrame`. Default: 'sample_id'.\n",
    "    normalize_bigwig: bool, optional\n",
    "            Whether bigwig files should be CPM normalized. Default: True.\n",
    "    remove_duplicates: bool, optional\n",
    "            Whether duplicates should be removed before converting the data to bigwig.\n",
    "    split_pattern: str\n",
    "            Pattern to split cell barcode from sample id. Default: ___ .\n",
    "    \"\"\"\n",
    "    # Create logger\n",
    "    level = logging.INFO\n",
    "    log_format = \"%(asctime)s %(name)-12s %(levelname)-8s %(message)s\"\n",
    "    handlers = [logging.StreamHandler(stream=sys.stdout)]\n",
    "    logging.basicConfig(level=level, format=log_format, handlers=handlers)\n",
    "    log = logging.getLogger(\"cisTopic\")\n",
    "\n",
    "    log.info(\"Creating pseudobulk for \" + str(group))\n",
    "    group_fragments_list = []\n",
    "    group_fragments_dict = {}\n",
    "    for sample_id in fragments_df_dict:\n",
    "        sample_data = cell_data[cell_data.loc[:, sample_id_col].isin([sample_id])]\n",
    "        if \"barcode\" in sample_data:\n",
    "            sample_data.index = sample_data[\"barcode\"].tolist()\n",
    "        else:\n",
    "            sample_data.index = prepare_tag_cells(\n",
    "                sample_data.index.tolist(), split_pattern\n",
    "            )\n",
    "        group_var = sample_data.iloc[:, 0]\n",
    "        barcodes = group_var[group_var.isin([group])].index.tolist()\n",
    "        fragments_df = fragments_df_dict[sample_id]\n",
    "        group_fragments = fragments_df.loc[fragments_df[\"Name\"].isin(barcodes)]\n",
    "        if len(fragments_df_dict) > 1:\n",
    "            group_fragments_dict[sample_id] = group_fragments\n",
    "\n",
    "    if len(fragments_df_dict) > 1:\n",
    "        group_fragments_list = [\n",
    "            group_fragments_dict[list(group_fragments_dict.keys())[x]]\n",
    "            for x in range(len(fragments_df_dict))\n",
    "        ]\n",
    "        group_fragments = group_fragments_list[0].append(group_fragments_list[1:])\n",
    "\n",
    "    del group_fragments_dict\n",
    "    del group_fragments_list\n",
    "    del fragments_df\n",
    "    gc.collect()\n",
    "\n",
    "    group_pr = pr.PyRanges(group_fragments)\n",
    "    if isinstance(bigwig_path, str):\n",
    "        bigwig_path_group = os.path.join(bigwig_path, str(group) + \".bw\")\n",
    "        if remove_duplicates:\n",
    "            group_pr.to_bigwig(\n",
    "                path=bigwig_path_group,\n",
    "                chromosome_sizes=chromsizes,\n",
    "                rpm=normalize_bigwig,\n",
    "            )\n",
    "        else:\n",
    "            group_pr.to_bigwig(\n",
    "                path=bigwig_path_group,\n",
    "                chromosome_sizes=chromsizes,\n",
    "                rpm=normalize_bigwig,\n",
    "                value_col=\"Score\",\n",
    "            )\n",
    "    if isinstance(bed_path, str):\n",
    "        print(\"here\")\n",
    "        print(group_pr)\n",
    "        bed_path_group = os.path.join(bed_path, str(group) + \".bed.gz\")\n",
    "        group_pr.to_bed(\n",
    "            path=bed_path_group, keep=False, compression=\"infer\", chain=False\n",
    "        )\n",
    "\n",
    "    log.info(str(group) + \" done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd9af64-4eb0-4e68-863e-934dc8112794",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f54b1f4-3e98-430f-aa12-1457dc70f632",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fragments_df_dict[\"ENCFF187VMN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21b7f1c-50dd-4464-9177-d4ede252d270",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "export_pseudobulk_one_sample(\n",
    "    cell_data,\n",
    "    groups[2],\n",
    "    fragments_df_dict,\n",
    "    chromsizes,\n",
    "    bigwig_path,\n",
    "    bed_path,\n",
    "    sample_id_col,\n",
    "    True,\n",
    "    True,\n",
    "    \"-\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acb8218-b6ca-4f34-bacc-03fbf5703fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [\n",
    "export_pseudobulk_one_sample(\n",
    "    cell_data,\n",
    "    group,\n",
    "    fragments_df_dict,\n",
    "    chromsizes,\n",
    "    bigwig_path,\n",
    "    bed_path,\n",
    "    sample_id_col,\n",
    "    True,\n",
    "    True,\n",
    "    \"-\",\n",
    ")\n",
    "for group in groups\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a628159-7d01-4119-8aa7-a2dbc0e57b58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pycisTopic.pseudobulk_peak_calling import export_pseudobulk\n",
    "bw_paths, bed_paths = export_pseudobulk(\n",
    "    input_data = test_cell_data,\n",
    "    variable = 'celltypes', # variable by which to generate pseubulk profiles, in this case we want pseudobulks per celltype\n",
    "    sample_id_col = 'sample_id',\n",
    "    chromsizes = chromsizes,\n",
    "    bed_path = os.path.join(work_dir, 'scATAC/consensus_peak_calling/pseudobulk_bed_files/'),  # specify where pseudobulk_bed_files should be stored\n",
    "    bigwig_path = os.path.join(work_dir, 'scATAC/consensus_peak_calling/pseudobulk_bw_files/'), # specify where pseudobulk_bw_files should be stored\n",
    "    path_to_fragments = test_fragments_dict, # location of fragment fiels\n",
    "    n_cpu = 1, # specify the number of cores to use, we use ray for multi processing\n",
    "    normalize_bigwig = True,\n",
    "    remove_duplicates = True,\n",
    "    _temp_dir = os.path.join(tmp_dir, 'ray_spill'),\n",
    "    split_pattern = '-'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be9c85e-8530-414d-a8b3-211fc9f1bc2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(cell_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8ac447-7c70-43da-869e-24d4c82a352d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cell_data[\"sample_id\"].isin(fragments_dict.keys()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4019af0-80d1-4d9c-bc9f-078f6b92609f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cell_data[\"celltype\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8a93d1b-b02c-4314-9714-8c4a42577ebf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T06:03:36.857095Z",
     "iopub.status.busy": "2023-01-15T06:03:36.856736Z",
     "iopub.status.idle": "2023-01-15T06:03:36.924444Z",
     "shell.execute_reply": "2023-01-15T06:03:36.923600Z",
     "shell.execute_reply.started": "2023-01-15T06:03:36.857068Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1990380/2069362678.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cell_data[\"barcode\"] = cell_data[\"atac_bc\"]\n"
     ]
    }
   ],
   "source": [
    "cell_data[\"barcode\"] = cell_data[\"atac_bc\"]\n",
    "cell_data = cell_data.set_index(\"atac_bc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3ab57bed-18d2-451d-b5bb-a89f5c824f74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T06:54:59.578917Z",
     "iopub.status.busy": "2023-01-15T06:54:59.578474Z",
     "iopub.status.idle": "2023-01-15T09:32:55.613317Z",
     "shell.execute_reply": "2023-01-15T09:32:55.612371Z",
     "shell.execute_reply.started": "2023-01-15T06:54:59.578888Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-14 22:54:59,585 cisTopic     INFO     Reading fragments from /cellar/users/aklie/data/igvf/topic_grn_links/mouse_adrenal/encode/fragments/ENCFF187VMN/encode_scatac_dcc_2/results/ENCSR525WPH-1/fragments/fragments.tsv.gz\n",
      "2023-01-14 22:56:44,138 cisTopic     INFO     Reading fragments from /cellar/users/aklie/data/igvf/topic_grn_links/mouse_adrenal/encode/fragments/ENCFF035SPT/encode_scatac_dcc_2/results/ENCSR713FPX-1/fragments/fragments.tsv.gz\n",
      "2023-01-14 22:58:25,383 cisTopic     INFO     Reading fragments from /cellar/users/aklie/data/igvf/topic_grn_links/mouse_adrenal/encode/fragments/ENCFF622EUO/encode_scatac_dcc_2/results/ENCSR858YSB-1/fragments/fragments.tsv.gz\n",
      "2023-01-14 23:00:24,434 cisTopic     INFO     Reading fragments from /cellar/users/aklie/data/igvf/topic_grn_links/mouse_adrenal/encode/fragments/ENCFF119IVK/encode_scatac_dcc_2/results/ENCSR400PXQ-1/fragments/fragments.tsv.gz\n",
      "2023-01-14 23:01:55,753 cisTopic     INFO     Reading fragments from /cellar/users/aklie/data/igvf/topic_grn_links/mouse_adrenal/encode/fragments/ENCFF683IBE/encode_scatac_dcc_2/results/ENCSR668VPD-1/fragments/fragments.tsv.gz\n",
      "2023-01-14 23:03:56,191 cisTopic     INFO     Reading fragments from /cellar/users/aklie/data/igvf/topic_grn_links/mouse_adrenal/encode/fragments/ENCFF042ZJI/encode_scatac_dcc_2/results/ENCSR736ABS-1/fragments/fragments.tsv.gz\n",
      "2023-01-14 23:05:45,716 cisTopic     INFO     Reading fragments from /cellar/users/aklie/data/igvf/topic_grn_links/mouse_adrenal/encode/fragments/ENCFF176LJV/encode_scatac_dcc_2/results/ENCSR834NRP-1/fragments/fragments.tsv.gz\n",
      "2023-01-14 23:07:43,911 cisTopic     INFO     Reading fragments from /cellar/users/aklie/data/igvf/topic_grn_links/mouse_adrenal/encode/fragments/ENCFF101BLM/encode_scatac_dcc_2/results/ENCSR024LKR-1/fragments/fragments.tsv.gz\n",
      "2023-01-14 23:09:27,214 cisTopic     INFO     Creating pseudobulk for Adipocytes\n",
      "2023-01-14 23:13:44,808 cisTopic     INFO     Adipocytes done!\n",
      "2023-01-14 23:13:44,992 cisTopic     INFO     Creating pseudobulk for Capsule\n",
      "2023-01-14 23:13:57,686 cisTopic     INFO     Capsule done!\n",
      "2023-01-14 23:13:57,695 cisTopic     INFO     Creating pseudobulk for Cortex\n",
      "2023-01-15 00:59:03,988 cisTopic     INFO     Cortex done!\n",
      "2023-01-15 00:59:08,161 cisTopic     INFO     Creating pseudobulk for Endothelial\n",
      "2023-01-15 01:12:19,987 cisTopic     INFO     Endothelial done!\n",
      "2023-01-15 01:12:20,496 cisTopic     INFO     Creating pseudobulk for Fibroblast\n",
      "2023-01-15 01:14:54,515 cisTopic     INFO     Fibroblast done!\n",
      "2023-01-15 01:14:54,575 cisTopic     INFO     Creating pseudobulk for Hepatocyte\n",
      "2023-01-15 01:15:01,065 cisTopic     INFO     Hepatocyte done!\n",
      "2023-01-15 01:15:01,067 cisTopic     INFO     Creating pseudobulk for Macrophages\n",
      "2023-01-15 01:16:52,776 cisTopic     INFO     Macrophages done!\n",
      "2023-01-15 01:16:52,819 cisTopic     INFO     Creating pseudobulk for Medulla\n",
      "2023-01-15 01:27:23,012 cisTopic     INFO     Medulla done!\n",
      "2023-01-15 01:27:23,200 cisTopic     INFO     Creating pseudobulk for Skeletal_muscle\n",
      "2023-01-15 01:27:27,106 cisTopic     INFO     Skeletal_muscle done!\n",
      "2023-01-15 01:27:27,107 cisTopic     INFO     Creating pseudobulk for Smooth_muscle\n",
      "2023-01-15 01:27:40,009 cisTopic     INFO     Smooth_muscle done!\n",
      "2023-01-15 01:27:40,015 cisTopic     INFO     Creating pseudobulk for Sox10_\n",
      "2023-01-15 01:28:20,816 cisTopic     INFO     Sox10_ done!\n",
      "2023-01-15 01:28:20,827 cisTopic     INFO     Creating pseudobulk for Stromal\n",
      "2023-01-15 01:32:55,037 cisTopic     INFO     Stromal done!\n"
     ]
    }
   ],
   "source": [
    "from pycisTopic.pseudobulk_peak_calling import export_pseudobulk\n",
    "bw_paths, bed_paths = export_pseudobulk(\n",
    "    input_data = cell_data,\n",
    "    variable = 'celltype', # variable by which to generate pseubulk profiles, in this case we want pseudobulks per celltype\n",
    "    sample_id_col = 'sample_id',\n",
    "    chromsizes = chromsizes,\n",
    "    bed_path = os.path.join(work_dir, 'scATAC/consensus_peak_calling/pseudobulk_bed_files/'),  # specify where pseudobulk_bed_files should be stored\n",
    "    bigwig_path = os.path.join(work_dir, 'scATAC/consensus_peak_calling/pseudobulk_bw_files/'), # specify where pseudobulk_bw_files should be stored\n",
    "    path_to_fragments = fragments_dict, # location of fragment fiels\n",
    "    n_cpu = 1, # specify the number of cores to use, we use ray for multi processing\n",
    "    normalize_bigwig = True,\n",
    "    remove_duplicates = True,\n",
    "    _temp_dir = os.path.join(tmp_dir, 'ray_spill'),\n",
    "    split_pattern = '-'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "739e8cb9-892f-466b-996e-c5d835f83775",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T09:32:55.615652Z",
     "iopub.status.busy": "2023-01-15T09:32:55.615327Z",
     "iopub.status.idle": "2023-01-15T09:32:55.627584Z",
     "shell.execute_reply": "2023-01-15T09:32:55.626851Z",
     "shell.execute_reply.started": "2023-01-15T09:32:55.615612Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(bed_paths,\n",
    "            open(os.path.join(work_dir, 'scATAC/consensus_peak_calling/pseudobulk_bed_files/bed_paths.pkl'), 'wb'))\n",
    "pickle.dump(bw_paths,\n",
    "           open(os.path.join(work_dir, 'scATAC/consensus_peak_calling/pseudobulk_bed_files/bw_paths.pkl'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fb42b7-59af-4250-b9e0-b42159b29a43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T15:53:08.774185Z",
     "iopub.status.busy": "2023-01-15T15:53:08.773873Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-15 07:53:26,502\tINFO worker.py:1519 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(macs_call_peak_ray pid=2044428)\u001b[0m 2023-01-15 07:53:39,567 cisTopic     INFO     Calling peaks for Stromal with /cellar/users/aklie/opt/miniconda3/envs/scenicplus/bin/macs2 callpeak --treatment mouse_adrenal/scATAC/consensus_peak_calling/pseudobulk_bed_files/Stromal.bed.gz --name Stromal  --outdir mouse_adrenal/scATAC/consensus_peak_calling/MACS/ --format BEDPE --gsize hs --qvalue 0.05 --nomodel --shift 73 --extsize 146 --keep-dup all --call-summits --nolambda\n",
      "\u001b[2m\u001b[36m(macs_call_peak_ray pid=2044425)\u001b[0m 2023-01-15 07:53:39,594 cisTopic     INFO     Calling peaks for Skeletal_muscle with /cellar/users/aklie/opt/miniconda3/envs/scenicplus/bin/macs2 callpeak --treatment mouse_adrenal/scATAC/consensus_peak_calling/pseudobulk_bed_files/Skeletal_muscle.bed.gz --name Skeletal_muscle  --outdir mouse_adrenal/scATAC/consensus_peak_calling/MACS/ --format BEDPE --gsize hs --qvalue 0.05 --nomodel --shift 73 --extsize 146 --keep-dup all --call-summits --nolambda\n",
      "\u001b[2m\u001b[36m(macs_call_peak_ray pid=2044422)\u001b[0m 2023-01-15 07:53:39,605 cisTopic     INFO     Calling peaks for Capsule with /cellar/users/aklie/opt/miniconda3/envs/scenicplus/bin/macs2 callpeak --treatment mouse_adrenal/scATAC/consensus_peak_calling/pseudobulk_bed_files/Capsule.bed.gz --name Capsule  --outdir mouse_adrenal/scATAC/consensus_peak_calling/MACS/ --format BEDPE --gsize hs --qvalue 0.05 --nomodel --shift 73 --extsize 146 --keep-dup all --call-summits --nolambda\n",
      "\u001b[2m\u001b[36m(macs_call_peak_ray pid=2044427)\u001b[0m 2023-01-15 07:53:39,579 cisTopic     INFO     Calling peaks for Medulla with /cellar/users/aklie/opt/miniconda3/envs/scenicplus/bin/macs2 callpeak --treatment mouse_adrenal/scATAC/consensus_peak_calling/pseudobulk_bed_files/Medulla.bed.gz --name Medulla  --outdir mouse_adrenal/scATAC/consensus_peak_calling/MACS/ --format BEDPE --gsize hs --qvalue 0.05 --nomodel --shift 73 --extsize 146 --keep-dup all --call-summits --nolambda\n",
      "\u001b[2m\u001b[36m(macs_call_peak_ray pid=2044431)\u001b[0m 2023-01-15 07:53:39,584 cisTopic     INFO     Calling peaks for Smooth_muscle with /cellar/users/aklie/opt/miniconda3/envs/scenicplus/bin/macs2 callpeak --treatment mouse_adrenal/scATAC/consensus_peak_calling/pseudobulk_bed_files/Smooth_muscle.bed.gz --name Smooth_muscle  --outdir mouse_adrenal/scATAC/consensus_peak_calling/MACS/ --format BEDPE --gsize hs --qvalue 0.05 --nomodel --shift 73 --extsize 146 --keep-dup all --call-summits --nolambda\n",
      "\u001b[2m\u001b[36m(macs_call_peak_ray pid=2044421)\u001b[0m 2023-01-15 07:53:39,669 cisTopic     INFO     Calling peaks for Cortex with /cellar/users/aklie/opt/miniconda3/envs/scenicplus/bin/macs2 callpeak --treatment mouse_adrenal/scATAC/consensus_peak_calling/pseudobulk_bed_files/Cortex.bed.gz --name Cortex  --outdir mouse_adrenal/scATAC/consensus_peak_calling/MACS/ --format BEDPE --gsize hs --qvalue 0.05 --nomodel --shift 73 --extsize 146 --keep-dup all --call-summits --nolambda\n",
      "\u001b[2m\u001b[36m(macs_call_peak_ray pid=2044430)\u001b[0m 2023-01-15 07:53:39,663 cisTopic     INFO     Calling peaks for Fibroblast with /cellar/users/aklie/opt/miniconda3/envs/scenicplus/bin/macs2 callpeak --treatment mouse_adrenal/scATAC/consensus_peak_calling/pseudobulk_bed_files/Fibroblast.bed.gz --name Fibroblast  --outdir mouse_adrenal/scATAC/consensus_peak_calling/MACS/ --format BEDPE --gsize hs --qvalue 0.05 --nomodel --shift 73 --extsize 146 --keep-dup all --call-summits --nolambda\n",
      "\u001b[2m\u001b[36m(macs_call_peak_ray pid=2044423)\u001b[0m 2023-01-15 07:53:39,654 cisTopic     INFO     Calling peaks for Sox10_ with /cellar/users/aklie/opt/miniconda3/envs/scenicplus/bin/macs2 callpeak --treatment mouse_adrenal/scATAC/consensus_peak_calling/pseudobulk_bed_files/Sox10_.bed.gz --name Sox10_  --outdir mouse_adrenal/scATAC/consensus_peak_calling/MACS/ --format BEDPE --gsize hs --qvalue 0.05 --nomodel --shift 73 --extsize 146 --keep-dup all --call-summits --nolambda\n",
      "\u001b[2m\u001b[36m(macs_call_peak_ray pid=2044429)\u001b[0m 2023-01-15 07:53:39,679 cisTopic     INFO     Calling peaks for Macrophages with /cellar/users/aklie/opt/miniconda3/envs/scenicplus/bin/macs2 callpeak --treatment mouse_adrenal/scATAC/consensus_peak_calling/pseudobulk_bed_files/Macrophages.bed.gz --name Macrophages  --outdir mouse_adrenal/scATAC/consensus_peak_calling/MACS/ --format BEDPE --gsize hs --qvalue 0.05 --nomodel --shift 73 --extsize 146 --keep-dup all --call-summits --nolambda\n",
      "\u001b[2m\u001b[36m(macs_call_peak_ray pid=2044426)\u001b[0m 2023-01-15 07:53:39,811 cisTopic     INFO     Calling peaks for Endothelial with /cellar/users/aklie/opt/miniconda3/envs/scenicplus/bin/macs2 callpeak --treatment mouse_adrenal/scATAC/consensus_peak_calling/pseudobulk_bed_files/Endothelial.bed.gz --name Endothelial  --outdir mouse_adrenal/scATAC/consensus_peak_calling/MACS/ --format BEDPE --gsize hs --qvalue 0.05 --nomodel --shift 73 --extsize 146 --keep-dup all --call-summits --nolambda\n",
      "\u001b[2m\u001b[36m(macs_call_peak_ray pid=2044424)\u001b[0m 2023-01-15 07:53:39,810 cisTopic     INFO     Calling peaks for Hepatocyte with /cellar/users/aklie/opt/miniconda3/envs/scenicplus/bin/macs2 callpeak --treatment mouse_adrenal/scATAC/consensus_peak_calling/pseudobulk_bed_files/Hepatocyte.bed.gz --name Hepatocyte  --outdir mouse_adrenal/scATAC/consensus_peak_calling/MACS/ --format BEDPE --gsize hs --qvalue 0.05 --nomodel --shift 73 --extsize 146 --keep-dup all --call-summits --nolambda\n",
      "\u001b[2m\u001b[36m(macs_call_peak_ray pid=2044420)\u001b[0m 2023-01-15 07:53:39,829 cisTopic     INFO     Calling peaks for Adipocytes with /cellar/users/aklie/opt/miniconda3/envs/scenicplus/bin/macs2 callpeak --treatment mouse_adrenal/scATAC/consensus_peak_calling/pseudobulk_bed_files/Adipocytes.bed.gz --name Adipocytes  --outdir mouse_adrenal/scATAC/consensus_peak_calling/MACS/ --format BEDPE --gsize hs --qvalue 0.05 --nomodel --shift 73 --extsize 146 --keep-dup all --call-summits --nolambda\n",
      "\u001b[2m\u001b[36m(macs_call_peak_ray pid=2044425)\u001b[0m 2023-01-15 07:53:46,810 cisTopic     INFO     Skeletal_muscle done!\n",
      "\u001b[2m\u001b[36m(macs_call_peak_ray pid=2044424)\u001b[0m 2023-01-15 07:53:48,470 cisTopic     INFO     Hepatocyte done!\n",
      "\u001b[2m\u001b[36m(macs_call_peak_ray pid=2044431)\u001b[0m 2023-01-15 07:54:02,094 cisTopic     INFO     Smooth_muscle done!\n",
      "\u001b[2m\u001b[36m(macs_call_peak_ray pid=2044422)\u001b[0m 2023-01-15 07:54:02,862 cisTopic     INFO     Capsule done!\n",
      "\u001b[2m\u001b[36m(macs_call_peak_ray pid=2044423)\u001b[0m 2023-01-15 07:54:33,188 cisTopic     INFO     Sox10_ done!\n",
      "\u001b[2m\u001b[36m(macs_call_peak_ray pid=2044429)\u001b[0m 2023-01-15 07:55:16,270 cisTopic     INFO     Macrophages done!\n",
      "\u001b[2m\u001b[36m(macs_call_peak_ray pid=2044430)\u001b[0m 2023-01-15 07:56:03,457 cisTopic     INFO     Fibroblast done!\n",
      "\u001b[2m\u001b[36m(macs_call_peak_ray pid=2044428)\u001b[0m 2023-01-15 07:56:38,317 cisTopic     INFO     Stromal done!\n",
      "\u001b[2m\u001b[36m(macs_call_peak_ray pid=2044420)\u001b[0m 2023-01-15 07:56:49,962 cisTopic     INFO     Adipocytes done!\n",
      "\u001b[2m\u001b[36m(macs_call_peak_ray pid=2044427)\u001b[0m 2023-01-15 07:59:06,210 cisTopic     INFO     Medulla done!\n",
      "\u001b[2m\u001b[36m(macs_call_peak_ray pid=2044426)\u001b[0m 2023-01-15 07:59:19,057 cisTopic     INFO     Endothelial done!\n"
     ]
    }
   ],
   "source": [
    "from pycisTopic.pseudobulk_peak_calling import peak_calling\n",
    "macs_path='/cellar/users/aklie/opt/miniconda3/envs/scenicplus/bin/macs2'\n",
    "# Run peak calling\n",
    "narrow_peaks_dict = peak_calling(macs_path,\n",
    "                                 bed_paths,\n",
    "                                 os.path.join(work_dir, 'scATAC/consensus_peak_calling/MACS/'),\n",
    "                                 genome_size='hs',\n",
    "                                 n_cpu=12,\n",
    "                                 input_format='BEDPE',\n",
    "                                 shift=73,\n",
    "                                 ext_size=146,\n",
    "                                 keep_dup = 'all',\n",
    "                                 q_value = 0.05,\n",
    "                                 _temp_dir = os.path.join(tmp_dir, 'ray_spill'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e0a6d419-3240-4047-9671-1609f4aeabd4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T15:52:39.435256Z",
     "iopub.status.busy": "2023-01-15T15:52:39.434869Z",
     "iopub.status.idle": "2023-01-15T15:52:41.533714Z",
     "shell.execute_reply": "2023-01-15T15:52:41.532873Z",
     "shell.execute_reply.started": "2023-01-15T15:52:39.435227Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ray\n",
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490cb343-0472-44f0-bd33-58e5f362aea1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pickle.dump(narrow_peaks_dict,\n",
    "            open(os.path.join(work_dir, 'scATAC/consensus_peak_calling/MACS/narrow_peaks_dict.pkl'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4357123-7202-4cdc-a038-39452d2388c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pycisTopic.iterative_peak_calling import *\n",
    "# Other param\n",
    "peak_half_width = 250\n",
    "path_to_blacklist= os.path.join(work_dir, 'hg38-blacklist.v2.bed')\n",
    "# Get consensus peaks\n",
    "consensus_peaks=get_consensus_peaks(narrow_peaks_dict, peak_half_width, chromsizes=chromsizes, path_to_blacklist=path_to_blacklist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e903b4-73da-40c0-b88a-4301a7f1000d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "consensus_peaks.to_bed(\n",
    "    path = os.path.join(work_dir, 'scATAC/consensus_peak_calling/consensus_regions.bed'),\n",
    "    keep=True,\n",
    "    compression='infer',\n",
    "    chain=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec2ae2b-78d8-4611-91af-915bd9c5d156",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pybiomart as pbm\n",
    "dataset = pbm.Dataset(name='mmusculus_gene_ensembl',  host='http://www.ensembl.org')\n",
    "annot = dataset.query(attributes=['chromosome_name', 'transcription_start_site', 'strand', 'external_gene_name', 'transcript_biotype'])\n",
    "annot['Chromosome/scaffold name'] = annot['Chromosome/scaffold name'].to_numpy(dtype = str)\n",
    "filter = annot['Chromosome/scaffold name'].str.contains('CHR|GL|JH|MT')\n",
    "annot = annot[~filter]\n",
    "annot['Chromosome/scaffold name'] = annot['Chromosome/scaffold name'].str.replace(r'(\\b\\S)', r'chr\\1')\n",
    "annot.columns=['Chromosome', 'Start', 'Strand', 'Gene', 'Transcript_type']\n",
    "annot = annot[annot.Transcript_type == 'protein_coding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d29510b-f90c-4829-a1c2-207f72361b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycisTopic.qc import *\n",
    "path_to_regions = {'10x_pbmc':os.path.join(work_dir, 'scATAC/consensus_peak_calling/consensus_regions.bed')}\n",
    "\n",
    "metadata_bc, profile_data_dict = compute_qc_stats(\n",
    "                fragments_dict = fragments_dict,\n",
    "                tss_annotation = annot,\n",
    "                stats=['barcode_rank_plot', 'duplicate_rate', 'insert_size_distribution', 'profile_tss', 'frip'],\n",
    "                label_list = None,\n",
    "                path_to_regions = path_to_regions,\n",
    "                n_cpu = 1,\n",
    "                valid_bc = None,\n",
    "                n_frag = 100,\n",
    "                n_bc = None,\n",
    "                tss_flank_window = 1000,\n",
    "                tss_window = 50,\n",
    "                tss_minimum_signal_window = 100,\n",
    "                tss_rolling_window = 10,\n",
    "                remove_duplicates = True,\n",
    "                _temp_dir = os.path.join(tmp_dir + 'ray_spill'))\n",
    "\n",
    "if not os.path.exists(os.path.join(work_dir, 'scATAC/quality_control')):\n",
    "    os.makedirs(os.path.join(work_dir, 'scATAC/quality_control'))\n",
    "\n",
    "pickle.dump(metadata_bc,\n",
    "            open(os.path.join(work_dir, 'scATAC/quality_control/metadata_bc.pkl'), 'wb'))\n",
    "\n",
    "pickle.dump(profile_data_dict,\n",
    "            open(os.path.join(work_dir, 'scATAC/quality_control/profile_data_dict.pkl'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0070e113-00a3-45bb-b619-fe37c9315185",
   "metadata": {},
   "outputs": [],
   "source": [
    "QC_filters = {\n",
    "    'Log_unique_nr_frag': [3.3 , None],\n",
    "    'FRIP':               [0.45, None],\n",
    "    'TSS_enrichment':     [5   , None],\n",
    "    'Dupl_rate':          [None, None]\n",
    "\n",
    "}\n",
    "\n",
    "# Return figure to plot together with other metrics, and cells passing filters. Figure will be saved as pdf.\n",
    "from pycisTopic.qc import *\n",
    "FRIP_NR_FRAG_fig, FRIP_NR_FRAG_filter=plot_barcode_metrics(metadata_bc['10x_pbmc'],\n",
    "                                       var_x='Log_unique_nr_frag',\n",
    "                                       var_y='FRIP',\n",
    "                                       min_x=QC_filters['Log_unique_nr_frag'][0],\n",
    "                                       max_x=QC_filters['Log_unique_nr_frag'][1],\n",
    "                                       min_y=QC_filters['FRIP'][0],\n",
    "                                       max_y=QC_filters['FRIP'][1],\n",
    "                                       return_cells=True,\n",
    "                                       return_fig=True,\n",
    "                                       plot=False)\n",
    "# Return figure to plot together with other metrics, and cells passing filters\n",
    "TSS_NR_FRAG_fig, TSS_NR_FRAG_filter=plot_barcode_metrics(metadata_bc['10x_pbmc'],\n",
    "                                      var_x='Log_unique_nr_frag',\n",
    "                                      var_y='TSS_enrichment',\n",
    "                                      min_x=QC_filters['Log_unique_nr_frag'][0],\n",
    "                                      max_x=QC_filters['Log_unique_nr_frag'][1],\n",
    "                                      min_y=QC_filters['TSS_enrichment'][0],\n",
    "                                      max_y=QC_filters['TSS_enrichment'][1],\n",
    "                                      return_cells=True,\n",
    "                                      return_fig=True,\n",
    "                                      plot=False)\n",
    "# Return figure to plot together with other metrics, but not returning cells (no filter applied for the duplication rate  per barcode)\n",
    "DR_NR_FRAG_fig=plot_barcode_metrics(metadata_bc['10x_pbmc'],\n",
    "                                      var_x='Log_unique_nr_frag',\n",
    "                                      var_y='Dupl_rate',\n",
    "                                      min_x=QC_filters['Log_unique_nr_frag'][0],\n",
    "                                      max_x=QC_filters['Log_unique_nr_frag'][1],\n",
    "                                      min_y=QC_filters['Dupl_rate'][0],\n",
    "                                      max_y=QC_filters['Dupl_rate'][1],\n",
    "                                      return_cells=False,\n",
    "                                      return_fig=True,\n",
    "                                      plot=False,\n",
    "                                      plot_as_hexbin = True)\n",
    "\n",
    "# Plot barcode stats in one figure\n",
    "fig=plt.figure(figsize=(10,10))\n",
    "plt.subplot(1, 3, 1)\n",
    "img = fig2img(FRIP_NR_FRAG_fig)\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 3, 2)\n",
    "img = fig2img(TSS_NR_FRAG_fig)\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 3, 3)\n",
    "img = fig2img(DR_NR_FRAG_fig)\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5f3787-6c60-4fbb-80a6-b3701ddc8f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_passing_filters = {'10x_pbmc':[]}\n",
    "bc_passing_filters['10x_pbmc'] = list((set(FRIP_NR_FRAG_filter) & set(TSS_NR_FRAG_filter)))\n",
    "pickle.dump(bc_passing_filters,\n",
    "            open(os.path.join(work_dir, 'scATAC/quality_control/bc_passing_filters.pkl'), 'wb'))\n",
    "print(f\"{len(bc_passing_filters['10x_pbmc'])} barcodes passed QC stats\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73e922a-16b3-434d-ad53-8a416209a936",
   "metadata": {},
   "source": [
    "## 4. pycisTopic analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9475e8b0-d62d-4bf4-a835-ff64f82daa40",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6357e41b-293f-4ead-91f0-7a4fb938d313",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 scenicplus",
   "language": "python",
   "name": "scenicplus"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
